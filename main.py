import streamlit as st
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain.memory import ConversationBufferMemory
from langchain.chains import RetrievalQA
from langchain.schema import Document

from llms.bili_deepseek import DeepSeekLLM  # ä½ çš„ DeepSeek æ¥å£

# -----------------------
# âœ… é¡µé¢è®¾ç½®
# -----------------------
st.set_page_config(page_title="ğŸ“š ç›´æ’­äº¤æ˜“çŸ¥è¯†åº“", layout="wide")
st.title("ğŸ“š ç›´æ’­äº¤æ˜“çŸ¥è¯†åº“")

# -----------------------
# âœ… Session åˆå§‹åŒ–
# -----------------------
if "messages" not in st.session_state:
    st.session_state.messages = []

if "vector_store" not in st.session_state:
    st.session_state.vector_store = None

if "uploaded_files_changed" not in st.session_state:
    st.session_state.uploaded_files_changed = False

if "last_uploaded_files" not in st.session_state:
    st.session_state.last_uploaded_files = []

# -----------------------
# âœ… ä¸Šä¼ æ–‡ä»¶åŒºåŸŸ
# -----------------------
uploaded_files = st.file_uploader(
    "ğŸ“ ä¸Šä¼ æ–‡ä»¶ï¼ˆæ”¯æŒ .txt / .mdï¼‰",
    type=["txt", "md"],
    accept_multiple_files=True
)

# åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°å‘é‡åº“
if uploaded_files:
    filenames = [f.name for f in uploaded_files]
    if filenames != st.session_state.last_uploaded_files:
        st.session_state.uploaded_files_changed = True
        st.session_state.last_uploaded_files = filenames
else:
    st.session_state.last_uploaded_files = []
    st.session_state.uploaded_files_changed = False

# -----------------------
# âœ… æ„å»º/æ›´æ–°å‘é‡åº“
# -----------------------
if st.session_state.vector_store is None or st.session_state.uploaded_files_changed:
    with st.spinner("ğŸ”„ æ­£åœ¨æ„å»ºçŸ¥è¯†åº“..."):
        splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")
        docs = []

        if uploaded_files:
            for uploaded_file in uploaded_files:
                content = uploaded_file.read().decode("utf-8")
                doc = Document(page_content=content, metadata={"filename": uploaded_file.name})
                docs.append(doc)
        else:
            loader = TextLoader("files/example.md", encoding="utf-8")
            docs = loader.load()

        chunks = splitter.split_documents(docs)
        if st.session_state.vector_store is None:
            st.session_state.vector_store = FAISS.from_documents(chunks, embeddings)
        else:
            st.session_state.vector_store.add_documents(chunks)
        st.session_state.uploaded_files_changed = False

    st.success("âœ… çŸ¥è¯†åº“å·²æ›´æ–°ï¼")

# -----------------------
# âœ… å±•ç¤ºå†å²å¯¹è¯
# -----------------------
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# -----------------------
# âœ… æ„å»º QA chain
# -----------------------
history = StreamlitChatMessageHistory()
memory = ConversationBufferMemory(
    chat_memory=history, return_messages=True, memory_key="chat_history", output_key="output"
)

retriever = st.session_state.vector_store.as_retriever(search_kwargs={"k": 3})
llm = DeepSeekLLM()
qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# -----------------------
# âœ… èŠå¤©è¾“å…¥ä¸å›å¤
# -----------------------
query = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜")

if query:
    st.session_state.messages.append({"role": "user", "content": query})
    st.chat_message("user").write(query)

    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤– æ€è€ƒä¸­..."):
            result = qa.run(query)
            st.markdown(result)

    st.session_state.messages.append({"role": "assistant", "content": result})
