# main.py
import streamlit as st
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA

from llms.deepseek import DeepSeekLLM  # âœ… å½“å‰ç”¨ DeepSeek
# from llms.bili_custom import BilibiliChatLLM  # âœ… åé¢åˆ‡æ¢å…¬å¸ LLM æ—¶æ”¹è¿™é‡Œ

st.set_page_config(page_title="RAG Demo", layout="wide")
st.title("ğŸ“š RAG æœ¬åœ°çŸ¥è¯†åº“é—®ç­”")

@st.cache_resource
def build_vector_store():
    loader = TextLoader("files/example.md", encoding="utf-8")
    docs = loader.load()
    chunks = CharacterTextSplitter(chunk_size=500, chunk_overlap=50).split_documents(docs)
    embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")
    return FAISS.from_documents(chunks, embeddings)

db = build_vector_store()
retriever = db.as_retriever(search_kwargs={"k": 3})
llm = DeepSeekLLM(api_key="sk-ecfb926379ba4f20b86002851135b95f")  # ğŸ‘ˆ å¡«ä½ çš„ DeepSeek Key
qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
query = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜")
if query:
    with st.spinner("æ€è€ƒä¸­..."):
        result = qa.run(query)
    st.success(result)
